{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at unikei/bert-base-proteins and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "\n",
    "# 导入其他文件\n",
    "from extract_features import load_features\n",
    "from models import BioNN, BioDeepNN, BioResNet\n",
    "from Model_Training import PeptidesDataLoader\n",
    "\n",
    "# constant\n",
    "SAVE = True\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# 处理数据\n",
    "# import data and preprocess\n",
    "data = pd.read_csv(\"./Data/processed_peptides10.csv\")  # load data\n",
    "\n",
    "# 得到氨基酸序列\n",
    "peptides = data.iloc[:, 0].values.tolist()  # 肽链的列表（字符串）\n",
    "\n",
    "# load extracted features\n",
    "features_x = load_features().iloc[:, 1:].values\n",
    "\n",
    "# 处理mmp y的数据\n",
    "all_mmp_y = data.iloc[:, 1:].values\n",
    "regular_coefficient = np.max(np.abs(all_mmp_y))\n",
    "all_mmp_y = all_mmp_y / regular_coefficient\n",
    "\n",
    "# import Bert-Base-Protein model\n",
    "checkpoint = 'unikei/bert-base-proteins'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(checkpoint)\n",
    "\n",
    "# 定义验证模型效果的函数\n",
    "model_class = BioResNet\n",
    "peptides = peptides\n",
    "features = features_x\n",
    "y = all_mmp_y\n",
    "kf = KFold(n_splits=5, random_state=33, shuffle=True)\n",
    "rg_errors = np.zeros((5, y.shape[1], 3))\n",
    "cl_errors = np.zeros((5, y.shape[1], 4))  # 评价指标包括auc, f1, precision, recall\n",
    "for i, (train_id, test_id) in enumerate(kf.split(features)):\n",
    "    train_peptides, train_features, train_y = [peptides[x] for x in train_id], torch.from_numpy(features[train_id]).float(), torch.from_numpy(y[train_id]).float()\n",
    "    test_peptides, test_features, test_y = [peptides[x] for x in test_id], torch.from_numpy(features[test_id]).float(), torch.from_numpy(y[test_id]).float()\n",
    "    train_dataloader = PeptidesDataLoader(train_peptides, train_features, train_y, 512, shuffle=True)\n",
    "    test_dataloader = PeptidesDataLoader(test_peptides, test_features, test_y, 512, shuffle=False)\n",
    "\n",
    "    # 初始化模型\n",
    "    bert_model = BertModel.from_pretrained(checkpoint).to(device)\n",
    "    bio_model = model_class(768 * 10 + features.shape[1]).to(device)\n",
    "    # 设置optimizer和criterion\n",
    "    train_bert_params = [id(bert_model.pooler.dense.bias), id(bert_model.pooler.dense.weight)]\n",
    "    bert_params = filter(lambda p: id(p) not in train_bert_params, bert_model.parameters())\n",
    "    optimizer = optim.Adam(\n",
    "        [\n",
    "            {\"params\": bert_params, \"lr\": 1e-6},\n",
    "            {\"params\": bert_model.pooler.dense.bias, \"lr\": 1e-3},\n",
    "            {\"params\": bert_model.pooler.dense.weight, \"lr\": 1e-3},\n",
    "            {\"params\": bio_model.parameters(), \"lr\": 1e-3}\n",
    "        ], lr=1e-3\n",
    "    )\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # 开始训练\n",
    "    bert_model.train()\n",
    "    bio_model.train()\n",
    "    train_epochs = 100\n",
    "    loss_track = []\n",
    "    for epoch in tqdm(range(train_epochs), total=train_epochs):\n",
    "        loss_track_epoch = []\n",
    "        for peptides_epoch, features_epoch, labels_epoch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            tokens_epoch = tokenizer(peptides_epoch, return_tensors='pt')\n",
    "            input_ids = tokens_epoch[\"input_ids\"].to(device)\n",
    "            attention_mask = tokens_epoch[\"attention_mask\"].to(device)\n",
    "            token_type_ids = tokens_epoch[\"token_type_ids\"].to(device)\n",
    "            bert_output = bert_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).last_hidden_state.view(len(peptides_epoch), -1)  # 将embed结果铺平\n",
    "            break\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ASGGMGNK'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peptides[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./Data/processed_peptides10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASGGMGNK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KIYNYDCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KIYDYDCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KIYDLDCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASGGLGNK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTYRYIDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18403</th>\n",
       "      <td>YPLHLQYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18404</th>\n",
       "      <td>YPLSLRSL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18405</th>\n",
       "      <td>YPRNIGGQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18406</th>\n",
       "      <td>YVRHLINN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18407</th>\n",
       "      <td>YYGELLVW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18408 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ASGGMGNK\n",
       "0      KIYNYDCE\n",
       "1      KIYDYDCE\n",
       "2      KIYDLDCE\n",
       "3      ASGGLGNK\n",
       "4      DTYRYIDY\n",
       "...         ...\n",
       "18403  YPLHLQYN\n",
       "18404  YPLSLRSL\n",
       "18405  YPRNIGGQ\n",
       "18406  YVRHLINN\n",
       "18407  YYGELLVW\n",
       "\n",
       "[18408 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./Cache/peptides.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 2,  6, 29,  ..., 44, 46,  3],\n",
       "        [ 2, 14, 47,  ..., 42, 32,  3],\n",
       "        [ 2, 14, 47,  ..., 42, 32,  3],\n",
       "        ...,\n",
       "        [ 2, 27, 33,  ..., 28, 40,  3],\n",
       "        [ 2, 27, 38,  ..., 44, 44,  3],\n",
       "        [ 2, 27, 35,  ..., 38, 43,  3]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(peptides, return_tensors='pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
