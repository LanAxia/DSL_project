{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51942593a4c55c4c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Extract Unique Peptides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695e16865c1a0b2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T20:32:18.870528100Z",
     "start_time": "2024-05-10T20:32:18.852528100Z"
    },
    "collapsed": true,
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "\n",
    "# 导入其他文件\n",
    "from extract_features import load_features, load_pred_features\n",
    "from models import BioNN, BioDeepNN, BioResNet\n",
    "from Model_Training import PeptidesDataLoader\n",
    "\n",
    "# constant\n",
    "SAVE = True\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3274979f049fda5c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31365edba01c8147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T19:17:52.775410300Z",
     "start_time": "2024-05-10T19:17:51.437530200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lanhongyi/opt/anaconda3/envs/dsl_project/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertModel were not initialized from the model checkpoint at unikei/bert-base-proteins and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BioDeepNN(\n",
       "  (nn1): Linear(in_features=10350, out_features=512, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (nn2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (nn3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (dropout3): Dropout(p=0.5, inplace=False)\n",
       "  (nn4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (dropout4): Dropout(p=0.5, inplace=False)\n",
       "  (nn5): Linear(in_features=256, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载Bert模型和Bio模型\n",
    "checkpoint = 'unikei/bert-base-proteins'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(checkpoint)\n",
    "\n",
    "bert_model = BertModel.from_pretrained(checkpoint).to(device)\n",
    "bert_model.load_state_dict(torch.load('./Model/bert_model.pth', map_location=device))\n",
    "bert_model.eval()\n",
    "\n",
    "bio_model = BioDeepNN(10350, labels_num=18).to(device)\n",
    "bio_model.load_state_dict(torch.load('./Model/bio_model.pth', map_location=device))\n",
    "bio_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb92ab8075130a50",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20bd0c77c5f667f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T19:33:23.294676800Z",
     "start_time": "2024-05-10T19:33:23.214167800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FGDLSVTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGEFLRTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FTSDYSKY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QGTFTSDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQDFVQWL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  FGDLSVTY\n",
       "1  LGEFLRTH\n",
       "2  FTSDYSKY\n",
       "3  QGTFTSDY\n",
       "4  AQDFVQWL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据(这一步会保存相关数据，后续无需再次运行)\n",
    "data = pd.read_csv(\"./Data/Protease_Peptides.csv\", sep=\"\\t\")\n",
    "data = data[(data.iloc[:, 1:] != \"-\").sum(axis=1) == 8]  # 删除含有\"-\"的数据行\n",
    "# 38727 rows，其中不重复的肽链有26794条，可能存在多个protease对应一个肽链\n",
    "\n",
    "# 将3位缩写的氨基酸转换为1位缩写\n",
    "amino_3_to_1 = dict()\n",
    "amino_table = pd.read_csv(\"./Data/amino_table.csv\", header=None, sep=\"\\t\")\n",
    "for i, x in amino_table.iterrows():\n",
    "    amino_3_to_1[x[3].lower()] = x[2]\n",
    "\n",
    "data.iloc[:, 1:] = data.iloc[:, 1:].map(lambda x: amino_3_to_1[x.lower()])\n",
    "\n",
    "# 生成peptides文件，用于让extract_features文件提取特征\n",
    "peptides = [\"\".join(x.tolist()) for i, x in data.iloc[:, 1:].iterrows()]\n",
    "peptides = pd.DataFrame(peptides)\n",
    "peptides.to_csv(\"./Cache/to_predict_peptides.csv\", index=False, header=None)\n",
    "peptides.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d6e748776122243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T21:35:37.747865100Z",
     "start_time": "2024-05-10T21:35:36.212129600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting binary features: 1944it [00:00, 457971.63it/s]\n",
      "Extracting cksaap features: 1944it [00:00, 57928.10it/s]\n",
      "Extracting binary features: 134it [00:00, 164868.51it/s]\n",
      "Extracting cksaap features: 134it [00:00, 32110.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# 加载peptides(MMP3独有的序列)\n",
    "mmp3_original_unique_peptides = pd.read_csv(\"./MMP3_unique_sequence.csv\", header=None)\n",
    "\n",
    "# 加载所有特征\n",
    "mmp3_features_x = load_pred_features(3).iloc[:, 1:].values  # 不保留peptides列\n",
    "mmp3_features_x = torch.from_numpy(mmp3_features_x).float()\n",
    "\n",
    "mmp3_original_unique_peptides = mmp3_original_unique_peptides.iloc[:, 0].values.tolist()\n",
    "mmp3_dataloader = PeptidesDataLoader(mmp3_original_unique_peptides, mmp3_features_x, np.zeros_like(mmp3_features_x), batch_size=512, shuffle=False)  # 填充labels，labels在这里是用不到的\n",
    "\n",
    "# 加载peptides(MMP9独有的序列)\n",
    "mmp9_original_unique_peptides = pd.read_csv(\"./MMP9_unique_sequence.csv\", header=None)\n",
    "\n",
    "# 加载所有特征\n",
    "mmp9_features_x = load_pred_features(9).iloc[:, 1:].values  # 不保留peptides列\n",
    "mmp9_features_x = torch.from_numpy(mmp9_features_x).float()\n",
    "\n",
    "mmp9_original_unique_peptides = mmp9_original_unique_peptides.iloc[:, 0].values.tolist()\n",
    "mmp9_dataloader = PeptidesDataLoader(mmp9_original_unique_peptides, mmp9_features_x, np.zeros_like(mmp9_features_x), batch_size=512, shuffle=False)  # 填"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "218f169e9fc6cfd8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 预测测试集的各MMP结果\n",
    "pred_mmp3 = []\n",
    "regular_coefficient = 6.82  # 这个值取决于训练时的regular_coefficient\n",
    "with torch.no_grad():\n",
    "    for peptides_epoch, features_epoch, _ in mmp3_dataloader:\n",
    "        tokens_epoch = tokenizer(peptides_epoch, return_tensors='pt').to(device)\n",
    "        bert_output = bert_model(**tokens_epoch).last_hidden_state.view(len(peptides_epoch), -1)  # 将embed结果铺平\n",
    "        bio_input = torch.cat([bert_output, features_epoch.to(device)], dim=1)\n",
    "\n",
    "        bio_output = bio_model(bio_input)\n",
    "        pred_mmp3.append(bio_output.to(\"cpu\"))\n",
    "pred_mmp3 = torch.cat(pred_mmp3, dim=0).detach().numpy() * regular_coefficient\n",
    "\n",
    "pred_mmp9 = []\n",
    "with torch.no_grad():\n",
    "    for peptides_epoch, features_epoch, _ in mmp9_dataloader:\n",
    "        tokens_epoch = tokenizer(peptides_epoch, return_tensors='pt').to(device)\n",
    "        bert_output = bert_model(**tokens_epoch).last_hidden_state.view(len(peptides_epoch), -1)  # 将embed结果铺平\n",
    "        bio_input = torch.cat([bert_output, features_epoch.to(device)], dim=1)\n",
    "\n",
    "        bio_output = bio_model(bio_input)\n",
    "        pred_mmp9.append(bio_output.to(\"cpu\"))\n",
    "pred_mmp9 = torch.cat(pred_mmp9, dim=0).detach().numpy() * regular_coefficient\n",
    "\n",
    "# 保存预测结果\n",
    "np.save(\"./Result/pred_mmp3.npy\", pred_mmp3)\n",
    "np.save(\"./Result/pred_mmp9.npy\", pred_mmp9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a02d4d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1944, 17)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mmp3 = np.concatenate([pred_mmp3[:, :2], pred_mmp3[:, 3:]], axis=1)\n",
    "pred_mmp3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9909044e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1349"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((pred_mmp3 > 0).sum(axis=1) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252e02a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "1944 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "369ced74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 17)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mmp9 = np.concatenate([pred_mmp9[:, :5], pred_mmp9[:, 6:]], axis=1)\n",
    "pred_mmp9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f71ab077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((pred_mmp9 > 0).sum(axis=1) > 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
