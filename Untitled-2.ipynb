{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "\n",
    "\n",
    "# 导入其他文件\n",
    "from extract_features import load_features, load_features_by_name\n",
    "from models import BioNN, BioDeepNN, BioResNet, LSTMFilter, CNNFilter, LSTMEncoder\n",
    "from Model_Training import PeptidesDataLoader, BertDataLoader\n",
    "\n",
    "# constant\n",
    "SAVE = True\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# 处理数据\n",
    "# import data and preprocess\n",
    "data = pd.read_csv(\"./Data/processed_peptides10.csv\")  # load data\n",
    "\n",
    "# 得到氨基酸序列\n",
    "peptides = data.iloc[:, 0].values.tolist()  # 肽链的列表（字符串）\n",
    "\n",
    "# load extracted features\n",
    "features_x = load_features_by_name([\"binary\", \"aac\", \"knn\"]).iloc[:, 1:].values\n",
    "\n",
    "# 处理mmp y的数据\n",
    "all_mmp_y = data.iloc[:, 1:].values\n",
    "regular_coefficient = np.max(np.abs(all_mmp_y))\n",
    "all_mmp_y = all_mmp_y / regular_coefficient\n",
    "\n",
    "# import Bert-Base-Protein model\n",
    "checkpoint = 'unikei/bert-base-proteins'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(checkpoint)\n",
    "\n",
    "# # 定义验证模型效果的函数\n",
    "# def validate_dl(model_class: nn.Module, peptides: list, features: np.array, y: np.array):\n",
    "#     # 用5折交叉验证来验证模型效果\n",
    "#     kf = KFold(n_splits=5, random_state=33, shuffle=True)\n",
    "#     rg_errors = np.zeros((5, y.shape[1], 3))\n",
    "#     cl_errors = np.zeros((5, y.shape[1], 4))  # 评价指标包括auc, f1, precision, recall\n",
    "#     tokens = tokenizer(peptides, return_tensors='pt')\n",
    "#     input_ids, attention_mask, token_type_ids = tokens[\"input_ids\"], tokens[\"attention_mask\"], tokens[\"token_type_ids\"]\n",
    "#     for i, (train_id, test_id) in enumerate(kf.split(features)):\n",
    "#         train_input_ids, train_attention_mask, train_token_type_ids, train_features, train_y = input_ids[train_id], attention_mask[train_id], token_type_ids[train_id], torch.from_numpy(features[train_id]).float(), torch.from_numpy(y[train_id]).float()\n",
    "#         test_input_ids, test_attention_mask, test_token_type_ids, test_features, test_y = input_ids[test_id], attention_mask[test_id], token_type_ids[test_id], torch.from_numpy(features[test_id]).float(), torch.from_numpy(y[test_id]).float()\n",
    "\n",
    "#         train_dataloader = BertDataLoader(train_input_ids, train_attention_mask, train_token_type_ids, train_features, train_y, 512, shuffle=True)\n",
    "#         test_dataloader = BertDataLoader(test_input_ids, test_attention_mask, test_token_type_ids, test_features, test_y, 512, shuffle=False)\n",
    "\n",
    "#         # 初始化模型\n",
    "#         bert_model = BertModel.from_pretrained(checkpoint).to(device)\n",
    "#         filter_model = LSTMFilter(768, 16).to(device)  # 输出是256维的\n",
    "#         bio_model = model_class(320 + features.shape[1]).to(device)\n",
    "#         # 设置optimizer和criterion\n",
    "#         train_bert_params = [id(bert_model.pooler.dense.bias), id(bert_model.pooler.dense.weight)]\n",
    "#         bert_params = filter(lambda p: id(p) not in train_bert_params, bert_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at unikei/bert-base-proteins and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(checkpoint).to(device)\n",
    "filter_model = LSTMFilter(768, 16).to(device)  # 输出是256维的\n",
    "# 设置optimizer和criterion\n",
    "train_bert_params = [id(bert_model.pooler.dense.bias), id(bert_model.pooler.dense.weight)]\n",
    "bert_params = filter(lambda p: id(p) not in train_bert_params, bert_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in bert_params:\n",
    "    x.requires_grad = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
